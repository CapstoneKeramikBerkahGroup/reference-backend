# Reference Management System - Backend API

Sistem pengelolaan dan analisis hubungan antar referensi ilmiah menggunakan FastAPI, PostgreSQL, dan NLP dengan dukungan integrasi Mendeley dan Zotero.

## ğŸš€ Features

- âœ… **Authentication & Authorization** (JWT-based)
  - Registrasi & login untuk Mahasiswa dan Dosen
  - Role-based access control
  - Profile management dengan bidang keahlian
  
- ğŸ“„ **Document Management**
  - Upload dokumen (PDF, DOCX)
  - Multi-source support (Manual Upload, Mendeley, Zotero)
  - Download & delete dokumen
  - Tag management
  - Advanced search and filtering
  
- ğŸ”— **Integration Services**
  - **Mendeley Integration** - OAuth2 authentication, library sync
  - **Zotero Integration** - API key authentication, automatic import
  - Token persistence and refresh handling
  - Duplicate prevention across sources
  
- ğŸ¤– **NLP Processing**
  - Indonesian language support with custom NLP
  - Automatic keyword extraction (lightweight)
  - Extractive text summarization
  - Reference extraction and validation
  - Research gap analysis
  
- ğŸ‘¥ **Pembimbingan System**
  - Request pembimbing workflow
  - Dosen-mahasiswa relationship management
  - Request approval/rejection with notes
  
- ğŸ“Š **Reference Management**
  - Automatic reference detection from documents
  - Reference validation by dosen
  - Status tracking (pending/validated/rejected)
  - Notes and feedback system
  
- ğŸ•¸ï¸ **Visualization**
  - Document similarity graph
  - Interactive network visualization data
  
## ğŸ› ï¸ Tech Stack

- **Framework**: FastAPI 0.109.0
- **Database**: PostgreSQL 15
- **Cache**: Redis 7
- **NLP**: Custom Indonesian NLP, spaCy, Sentence Transformers
- **Authentication**: JWT (python-jose)
- **ORM**: SQLAlchemy 2.0
- **Integrations**: Mendeley API (OAuth2), Zotero API
- **Email**: SMTP (MailHog for development)
- **File Processing**: PyPDF2, python-docx

## ğŸ“¦ Installation

### Prerequisites

- Docker & Docker Compose
- Python 3.11+ (if running locally)

### Quick Start with Docker

1. **Clone repository**
```bash
cd backend
```

2. **Copy environment file**
```bash
copy .env.example .env
```

3. **Build and run containers**
```bash
docker-compose up --build
```

4. **API will be available at:**
- API: http://localhost:8000
- Docs: http://localhost:8000/docs
- PostgreSQL: localhost:5432
- Redis: localhost:6379

### Local Development (without Docker)

1. **Create virtual environment**
```bash
python -m venv venv
venv\Scripts\activate
```

2. **Install dependencies**
```bash
pip install -r requirements.txt
python -m spacy download en_core_web_sm
```

3. **Setup PostgreSQL & Redis**
```bash
# Install PostgreSQL and Redis locally
# Update DATABASE_URL and REDIS_URL in .env
```

4. **Run application**
```bash
uvicorn app.main:app --reload
```

## ğŸ“š API Documentation

### Authentication Endpoints

#### Register Mahasiswa
```http
POST /api/auth/register/mahasiswa
Content-Type: application/json

{
  "nim": "1202223217",
  "program_studi": "Sistem Informasi",
  "angkatan": 2022,
  "user": {
    "email": "dhimmas@student.telkomuniversity.ac.id",
    "nama": "Dhimmas Parikesit",
    "password": "password123",
    "role": "mahasiswa"
  }
}
```

#### Register Dosen
```http
POST /api/auth/register/dosen
Content-Type: application/json

{
  "nip": "198001012020121001",
  "departemen": "Sistem Informasi",
  "user": {
    "email": "dosen@telkomuniversity.ac.id",
    "nama": "Dr. Taufik Nur Adi",
    "password": "password123",
    "role": "dosen"
  }
}
```

#### Login
```http
POST /api/auth/login
Content-Type: application/x-www-form-urlencoded

username=dhimmas@student.telkomuniversity.ac.id&password=password123
```

Response:
```json
{
  "access_token": "eyJhbGci...",
  "token_type": "bearer"
}
```

#### Get Current User
```http
GET /api/auth/me
Authorization: Bearer {token}
```

### Document Management

#### Upload Document
```http
POST /api/documents/upload
Authorization: Bearer {token}
Content-Type: multipart/form-data

file: [PDF/DOCX file]
judul: "Machine Learning in Healthcare"
```

#### Get All Documents
```http
GET /api/documents/
Authorization: Bearer {token}
```

#### Get Document by ID
```http
GET /api/documents/{dokumen_id}
Authorization: Bearer {token}
```

#### Download Document
```http
GET /api/documents/{dokumen_id}/download
Authorization: Bearer {token}
```

#### Delete Document
```http
DELETE /api/documents/{dokumen_id}
Authorization: Bearer {token}
```

#### Add Tag to Document
```http
POST /api/documents/{dokumen_id}/tags
Authorization: Bearer {token}
Content-Type: application/json

{
  "nama": "machine-learning"
}
```

#### Search Documents
```http
GET /api/documents/search/?q=machine+learning
Authorization: Bearer {token}
```

### NLP Processing

#### Extract Keywords
```http
POST /api/nlp/extract-keywords
Authorization: Bearer {token}
Content-Type: application/json

{
  "dokumen_id": 1,
  "top_k": 10
}
```

#### Generate Summary
```http
POST /api/nlp/summarize
Authorization: Bearer {token}
Content-Type: application/json

{
  "dokumen_id": 1,
  "max_length": 150,
  "min_length": 50
}
```

#### Process Document (Background)
```http
POST /api/nlp/process/{dokumen_id}
Authorization: Bearer {token}
```

#### Check Processing Status
```http
GET /api/nlp/status/{dokumen_id}
Authorization: Bearer {token}
```

### Visualization

#### Get Document Graph
```http
GET /api/visualization/graph?min_similarity=0.3
Authorization: Bearer {token}
```

Response:
```json
{
  "nodes": [
    {
      "id": 1,
      "label": "Machine Learning Research",
      "tags": ["ml", "ai"],
      "keywords": ["neural", "network", "deep learning"]
    }
  ],
  "edges": [
    {
      "source": 1,
      "target": 2,
      "weight": 0.85
    }
  ]
}
```

#### Get Similar Documents
```http
GET /api/visualization/similarity/{dokumen_id}?limit=5
Authorization: Bearer {token}
```

## ğŸ—„ï¸ Database Schema

### Main Tables
- `users` - User accounts (email, password, role)
- `mahasiswa` - Student profiles (NIM, program, angkatan, bidang_keahlian)
- `dosen` - Lecturer profiles (NIP, departemen, bidang_keahlian, max_bimbingan)
- `dokumen` - Documents/references (judul, file_path, source: manual/mendeley/zotero)
- `tag` - Document tags
- `kata_kunci` - Keywords extracted from documents
- `referensi` - References with validation status
- `catatan` - Lecturer validation notes
- `document_similarity` - Similarity scores between documents
- `pembimbing_request` - Guidance requests (status, messages)
- `pembimbing_mahasiswa` - Active guidance relationships

### Integration Tables
- `mendeley_tokens` - Mendeley OAuth tokens (access_token, refresh_token, expires_at)
- `zotero_config` - Zotero API configuration (user_id, api_key)

### Key Relationships
- User â†’ Mahasiswa/Dosen (1:1)
- Mahasiswa â†’ Dokumen (1:N)
- Mahasiswa â†” Dosen via pembimbing_request & pembimbing_mahasiswa
- Dokumen â†” Tag (N:M)
- Dokumen â†” KataKunci (N:M)
- Dokumen â†’ Referensi (1:N)
- Referensi â†’ Catatan (1:N)

## ğŸ§ª Testing

### Using Swagger UI
Visit http://localhost:8000/docs for interactive API testing

### Using curl
```bash
# Login
curl -X POST "http://localhost:8000/api/auth/login" \
  -H "Content-Type: application/x-www-form-urlencoded" \
  -d "username=user@example.com&password=password123"

# Upload document
curl -X POST "http://localhost:8000/api/documents/upload" \
  -H "Authorization: Bearer {token}" \
  -F "file=@paper.pdf" \
  -F "judul=Research Paper"
```

## ğŸ”§ Configuration

Edit `.env` file:

```env
# Database
POSTGRES_USER=admin
POSTGRES_PASSWORD=admin123
POSTGRES_DB=reference_system
DATABASE_URL=postgresql://admin:admin123@localhost:5432/reference_system

# Redis
REDIS_URL=redis://localhost:6379/0

# JWT
SECRET_KEY=your-secret-key-here
ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=30

# File Upload
MAX_FILE_SIZE_MB=10
ALLOWED_EXTENSIONS=pdf,docx
UPLOAD_DIR=uploads

# Integration APIs
MENDELEY_CLIENT_ID=your-mendeley-client-id
MENDELEY_CLIENT_SECRET=your-mendeley-client-secret
MENDELEY_REDIRECT_URI=http://localhost:3000/dashboard

# Email (Development with MailHog)
SMTP_HOST=localhost
SMTP_PORT=1025
SMTP_USERNAME=
SMTP_PASSWORD=
SMTP_FROM_EMAIL=noreply@refmanager.com

# NLP Settings
USE_LIGHTWEIGHT_NLP=true
KEYWORD_EXTRACTION_TOP_K=10
SUMMARY_SENTENCES=3
```

## ğŸ“ Project Structure

```
backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/              # API endpoints
â”‚   â”‚   â”œâ”€â”€ auth.py       # Authentication endpoints
â”‚   â”‚   â”œâ”€â”€ documents.py  # Document management
â”‚   â”‚   â”œâ”€â”€ nlp.py        # NLP processing
â”‚   â”‚   â”œâ”€â”€ users.py      # User management
â”‚   â”‚   â”œâ”€â”€ dosen.py      # Dosen-specific endpoints
â”‚   â”‚   â”œâ”€â”€ pembimbing.py # Guidance system
â”‚   â”‚   â”œâ”€â”€ integration.py # Mendeley/Zotero integration
â”‚   â”‚   â”œâ”€â”€ mendeley.py   # Mendeley OAuth callbacks
â”‚   â”‚   â””â”€â”€ visualization.py # Graph data
â”‚   â”œâ”€â”€ core/             # Core configurations
â”‚   â”‚   â”œâ”€â”€ config.py     # Settings
â”‚   â”‚   â”œâ”€â”€ database.py   # Database connection
â”‚   â”‚   â””â”€â”€ security.py   # JWT & password hashing
â”‚   â”œâ”€â”€ models/           # SQLAlchemy models
â”‚   â”‚   â””â”€â”€ models.py     # All database models
â”‚   â”œâ”€â”€ schemas/          # Pydantic schemas
â”‚   â”‚   â”œâ”€â”€ user_schemas.py
â”‚   â”‚   â””â”€â”€ document_schemas.py
â”‚   â”œâ”€â”€ services/         # Business logic
â”‚   â”‚   â”œâ”€â”€ nlp_service.py      # NLP processing
â”‚   â”‚   â”œâ”€â”€ custom_nlp.py       # Indonesian NLP
â”‚   â”‚   â”œâ”€â”€ mendeley_service.py # Mendeley integration
â”‚   â”‚   â”œâ”€â”€ zotero_service.py   # Zotero integration
â”‚   â”‚   â”œâ”€â”€ email_service.py    # Email notifications
â”‚   â”‚   â””â”€â”€ redis_service.py    # Redis caching
â”‚   â””â”€â”€ main.py           # FastAPI application
â”œâ”€â”€ uploads/              # Uploaded files (organized by user)
â”œâ”€â”€ logs/                 # Application logs
â”œâ”€â”€ Dockerfile            # Docker configuration
â”œâ”€â”€ docker-compose.yml    # Multi-container setup
â”œâ”€â”€ requirements.txt      # Python dependencies
â””â”€â”€ .env                  # Environment variables
```

## ğŸ³ Docker Commands

```bash
# Start services
docker-compose up -d

# View logs
docker-compose logs -f backend

# Stop services
docker-compose down

# Rebuild containers
docker-compose up --build

# Access database
docker exec -it reference_db psql -U admin -d reference_system

# Access backend shell
docker exec -it reference_backend bash
```

## ğŸš¨ Troubleshooting

### Port already in use
```bash
# Stop existing containers
docker-compose down

# Check ports
netstat -ano | findstr :8000
netstat -ano | findstr :5432
```

### Database connection error
```bash
# Check database is running
docker-compose ps

# Restart database
docker-compose restart db
```

### NLP models not downloading
```bash
# Download manually inside container
docker exec -it reference_backend python -m spacy download en_core_web_sm
```

## ğŸ“ License

MIT License - Telkom University Capstone Project 2025

## ğŸ‘¥ Contributors

- Dhimmas Parikesit (1202223217)
- Alisha Deanova Oemar (1202223105)
- Balqis Eka Nurfadisyah (1202220223)

## ğŸ“ Support

For issues and questions, please contact: dhimmas@student.telkomuniversity.ac.id
